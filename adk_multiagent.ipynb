{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmw6ToNA9sMHgkab7/el25",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evkumar71/agentic-ai/blob/main/adk_multiagent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ziOpqX4gdycP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39c6963a-8c28-48eb-a7ae-9cd1a242a06c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/14.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/14.6 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/14.6 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m12.7/14.6 MB\u001b[0m \u001b[31m163.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m139.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m139.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/278.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.1/278.1 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstallation complete.\n"
          ]
        }
      ],
      "source": [
        "!pip install google-adk -q\n",
        "!pip install litellm -q\n",
        "print(\"Installation complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Import necessary libraries\n",
        "import os\n",
        "import asyncio\n",
        "from google.adk.agents import Agent\n",
        "from google.adk.models.lite_llm import LiteLlm # For multi-model support\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.runners import Runner\n",
        "from google.genai import types # For creating message Content/Parts\n",
        "\n",
        "import warnings\n",
        "# Ignore all warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "print(\"Libraries imported.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gogSN0fHe8QS",
        "outputId": "cf79404e-5825-48e2-bef3-a8a4be0eb5d3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ['OPENAI_API_KEY']= userdata.get('OPENAI_API_KEY')\n",
        "os.environ['ANTHROPIC_API_KEY'] = userdata.get('ANTHROPIC_API_KEY')\n",
        "\n",
        "# --- Verify Keys (Optional Check) ---\n",
        "print(\"API Keys Set:\")\n",
        "print(f\"Google API Key set: {'Yes' if os.environ.get('GOOGLE_API_KEY') and os.environ['GOOGLE_API_KEY'] != 'YOUR_GOOGLE_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n",
        "print(f\"OpenAI API Key set: {'Yes' if os.environ.get('OPENAI_API_KEY') and os.environ['OPENAI_API_KEY'] != 'YOUR_OPENAI_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n",
        "print(f\"Anthropic API Key set: {'Yes' if os.environ.get('ANTHROPIC_API_KEY') and os.environ['ANTHROPIC_API_KEY'] != 'YOUR_ANTHROPIC_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n",
        "\n",
        "# Configure ADK to use API keys directly (not Vertex AI for this multi-model setup)\n",
        "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"False\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxO3pblbgYZP",
        "outputId": "b700ed1f-4d14-4d9b-b180-07a651d10c04"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Keys Set:\n",
            "Google API Key set: Yes\n",
            "OpenAI API Key set: Yes\n",
            "Anthropic API Key set: Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Define Model Constants for easier use ---\n",
        "\n",
        "# More supported models can be referenced here: https://ai.google.dev/gemini-api/docs/models#model-variations\n",
        "MODEL_GEMINI_2_5_FLASH = \"gemini-2.5-flash\"\n",
        "\n",
        "# More supported models can be referenced here: https://docs.litellm.ai/docs/providers/openai#openai-chat-completion-models\n",
        "MODEL_GPT_4O = \"openai/gpt-4.1\" # You can also try: gpt-4.1-mini, gpt-4o etc.\n",
        "\n",
        "# More supported models can be referenced here: https://docs.litellm.ai/docs/providers/anthropic\n",
        "MODEL_CLAUDE_SONNET = \"anthropic/claude-sonnet-4-20250514\" # You can also try: claude-opus-4-20250514 , claude-3-7-sonnet-20250219 etc\n",
        "\n",
        "print(\"\\nEnvironment configured.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0BOFkealbRW",
        "outputId": "59534279-3d96-436b-9df1-daa970dfce5d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Environment configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define the get_weather Tool\n",
        "def get_weather(city: str) -> dict:\n",
        "    \"\"\"Retrieves the current weather report for a specified city.\n",
        "\n",
        "    Args:\n",
        "        city (str): The name of the city (e.g., \"New York\", \"London\", \"Tokyo\").\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the weather information.\n",
        "              Includes a 'status' key ('success' or 'error').\n",
        "              If 'success', includes a 'report' key with weather details.\n",
        "              If 'error', includes an 'error_message' key.\n",
        "    \"\"\"\n",
        "    print(f\"--- Tool: get_weather called for city: {city} ---\") # Log tool execution\n",
        "    city_normalized = city.lower().replace(\" \", \"\") # Basic normalization\n",
        "\n",
        "    # Mock weather data\n",
        "    mock_weather_db = {\n",
        "        \"newyork\": {\"status\": \"success\", \"report\": \"The weather in New York is sunny with a temperature of 25°C.\"},\n",
        "        \"london\": {\"status\": \"success\", \"report\": \"It's cloudy in London with a temperature of 15°C.\"},\n",
        "        \"tokyo\": {\"status\": \"success\", \"report\": \"Tokyo is experiencing light rain and a temperature of 18°C.\"},\n",
        "    }\n",
        "\n",
        "    if city_normalized in mock_weather_db:\n",
        "        return mock_weather_db[city_normalized]\n",
        "    else:\n",
        "        return {\"status\": \"error\", \"error_message\": f\"Sorry, I don't have weather information for '{city}'.\"}\n",
        "\n",
        "# Example tool usage (optional test)\n",
        "print(get_weather(\"New York\"))\n",
        "print(get_weather(\"Paris\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kwbzIeAfjvf",
        "outputId": "f7151bae-dd38-4729-bbcf-18283128d46e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tool: get_weather called for city: New York ---\n",
            "{'status': 'success', 'report': 'The weather in New York is sunny with a temperature of 25°C.'}\n",
            "--- Tool: get_weather called for city: Paris ---\n",
            "{'status': 'error', 'error_message': \"Sorry, I don't have weather information for 'Paris'.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define the Weather Agent\n",
        "# Use one of the model constants defined earlier\n",
        "AGENT_MODEL = MODEL_GEMINI_2_5_FLASH # Starting with Gemini\n",
        "\n",
        "weather_agent = Agent(\n",
        "    name=\"weather_agent_v1\",\n",
        "    model=AGENT_MODEL, # Can be a string for Gemini or a LiteLlm object\n",
        "    description=\"Provides weather information for specific cities.\",\n",
        "    instruction=\"You are a helpful weather assistant. \"\n",
        "                \"When the user asks for the weather in a specific city, \"\n",
        "                \"use the 'get_weather' tool to find the information. \"\n",
        "                \"If the tool returns an error, inform the user politely. \"\n",
        "                \"If the tool is successful, present the weather report clearly.\",\n",
        "    tools=[get_weather], # Pass the function directly\n",
        ")\n",
        "\n",
        "print(f\"Agent '{weather_agent.name}' created using model '{AGENT_MODEL}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYZXOG4Pj7Vi",
        "outputId": "f543014b-0a85-42a0-e33e-0c621b7aeb04"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent 'weather_agent_v1' created using model 'gemini-2.5-flash'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Setup Session Service and Runner\n",
        "\n",
        "# --- Session Management ---\n",
        "# Key Concept: SessionService stores conversation history & state.\n",
        "# InMemorySessionService is simple, non-persistent storage for this tutorial.\n",
        "session_service = InMemorySessionService()\n",
        "\n",
        "# Define constants for identifying the interaction context\n",
        "APP_NAME = \"weather_tutorial_app\"\n",
        "USER_ID = \"user_1\"\n",
        "SESSION_ID = \"session_001\" # Using a fixed ID for simplicity\n",
        "\n",
        "# Create the specific session where the conversation will happen\n",
        "session = await session_service.create_session(\n",
        "    app_name=APP_NAME,\n",
        "    user_id=USER_ID,\n",
        "    session_id=SESSION_ID\n",
        ")\n",
        "print(f\"Session created: App='{APP_NAME}', User='{USER_ID}', Session='{SESSION_ID}'\")\n",
        "\n",
        "# --- OR ---\n",
        "\n",
        "# Uncomment the following lines if running as a standard Python script (.py file):\n",
        "\n",
        "# async def init_session(app_name:str,user_id:str,session_id:str) -> InMemorySessionService:\n",
        "#     session = await session_service.create_session(\n",
        "#         app_name=app_name,\n",
        "#         user_id=user_id,\n",
        "#         session_id=session_id\n",
        "#     )\n",
        "#     print(f\"Session created: App='{app_name}', User='{user_id}', Session='{session_id}'\")\n",
        "#     return session\n",
        "#\n",
        "# session = asyncio.run(init_session(APP_NAME,USER_ID,SESSION_ID))\n",
        "\n",
        "# --- Runner ---\n",
        "# Key Concept: Runner orchestrates the agent execution loop.\n",
        "runner = Runner(\n",
        "    agent=weather_agent, # The agent we want to run\n",
        "    app_name=APP_NAME,   # Associates runs with our app\n",
        "    session_service=session_service # Uses our session manager\n",
        ")\n",
        "print(f\"Runner created for agent '{runner.agent.name}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6PKtoA8mTas",
        "outputId": "80b78835-614e-4497-f860-50dd73ab569d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Session created: App='weather_tutorial_app', User='user_1', Session='session_001'\n",
            "Runner created for agent 'weather_agent_v1'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define Agent Interaction Function\n",
        "\n",
        "from google.genai import types # For creating message Content/Parts\n",
        "\n",
        "async def call_agent_async(query: str, runner, user_id, session_id):\n",
        "  \"\"\"Sends a query to the agent and prints the final response.\"\"\"\n",
        "  print(f\"\\n>>> User Query: {query}\")\n",
        "\n",
        "  # Prepare the user's message in ADK format\n",
        "  content = types.Content(role='user', parts=[types.Part(text=query)])\n",
        "\n",
        "  final_response_text = \"Agent did not produce a final response.\" # Default\n",
        "\n",
        "  # Key Concept: run_async executes the agent logic and yields Events.\n",
        "  # We iterate through events to find the final answer.\n",
        "  async for event in runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n",
        "      # You can uncomment the line below to see *all* events during execution\n",
        "      # print(f\"  [Event] Author: {event.author}, Type: {type(event).__name__}, Final: {event.is_final_response()}, Content: {event.content}\")\n",
        "\n",
        "      # Key Concept: is_final_response() marks the concluding message for the turn.\n",
        "      if event.is_final_response():\n",
        "          if event.content and event.content.parts:\n",
        "             # Assuming text response in the first part\n",
        "             final_response_text = event.content.parts[0].text\n",
        "          elif event.actions and event.actions.escalate: # Handle potential errors/escalations\n",
        "             final_response_text = f\"Agent escalated: {event.error_message or 'No specific message.'}\"\n",
        "          # Add more checks here if needed (e.g., specific error codes)\n",
        "          break # Stop processing events once the final response is found\n",
        "\n",
        "  print(f\"<<< Agent Response: {final_response_text}\")"
      ],
      "metadata": {
        "id": "aOl2XUzwqz1M"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run the Initial Conversation\n",
        "\n",
        "# We need an async function to await our interaction helper\n",
        "async def run_conversation():\n",
        "    await call_agent_async(\"What is the weather like in London?\",\n",
        "                                       runner=runner,\n",
        "                                       user_id=USER_ID,\n",
        "                                       session_id=SESSION_ID)\n",
        "\n",
        "    await call_agent_async(\"How about Paris?\",\n",
        "                                       runner=runner,\n",
        "                                       user_id=USER_ID,\n",
        "                                       session_id=SESSION_ID) # Expecting the tool's error message\n",
        "\n",
        "    await call_agent_async(\"Tell me the weather in New York\",\n",
        "                                       runner=runner,\n",
        "                                       user_id=USER_ID,\n",
        "                                       session_id=SESSION_ID)\n",
        "\n",
        "# Execute the conversation using await in an async context (like Colab/Jupyter)\n",
        "await run_conversation()\n",
        "\n",
        "# --- OR ---\n",
        "\n",
        "# Uncomment the following lines if running as a standard Python script (.py file):\n",
        "# import asyncio\n",
        "# if __name__ == \"__main__\":\n",
        "#     try:\n",
        "#         asyncio.run(run_conversation())\n",
        "#     except Exception as e:\n",
        "#         print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgtuWRNWr8dG",
        "outputId": "56d16a1d-baf6-47c6-97a7-fdedfb0df270"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> User Query: What is the weather like in London?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tool: get_weather called for city: London ---\n",
            "<<< Agent Response: The weather in London is cloudy with a temperature of 15°C.\n",
            "\n",
            ">>> User Query: How about Paris?\n",
            "--- Tool: get_weather called for city: Paris ---\n",
            "<<< Agent Response: Sorry, I don't have weather information for Paris. Is there another city you'd like to check?\n",
            "\n",
            ">>> User Query: Tell me the weather in New York\n",
            "--- Tool: get_weather called for city: New York ---\n",
            "<<< Agent Response: The weather in New York is sunny with a temperature of 25°C.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define and Test GPT Agent\n",
        "\n",
        "# Make sure 'get_weather' function from Step 1 is defined in your environment.\n",
        "# Make sure 'call_agent_async' is defined from earlier.\n",
        "\n",
        "# --- Agent using GPT-4o ---\n",
        "weather_agent_gpt = None # Initialize to None\n",
        "runner_gpt = None      # Initialize runner to None\n",
        "\n",
        "try:\n",
        "    weather_agent_gpt = Agent(\n",
        "        name=\"weather_agent_gpt\",\n",
        "        # Key change: Wrap the LiteLLM model identifier\n",
        "        model=LiteLlm(model=MODEL_GPT_4O),\n",
        "        description=\"Provides weather information (using GPT-4o).\",\n",
        "        instruction=\"You are a helpful weather assistant powered by GPT-4o. \"\n",
        "                    \"Use the 'get_weather' tool for city weather requests. \"\n",
        "                    \"Clearly present successful reports or polite error messages based on the tool's output status.\",\n",
        "        tools=[get_weather], # Re-use the same tool\n",
        "    )\n",
        "    print(f\"Agent '{weather_agent_gpt.name}' created using model '{MODEL_GPT_4O}'.\")\n",
        "\n",
        "    # InMemorySessionService is simple, non-persistent storage for this tutorial.\n",
        "    session_service_gpt = InMemorySessionService() # Create a dedicated service\n",
        "\n",
        "    # Define constants for identifying the interaction context\n",
        "    APP_NAME_GPT = \"weather_tutorial_app_gpt\" # Unique app name for this test\n",
        "    USER_ID_GPT = \"user_1_gpt\"\n",
        "    SESSION_ID_GPT = \"session_001_gpt\" # Using a fixed ID for simplicity\n",
        "\n",
        "    # Create the specific session where the conversation will happen\n",
        "    session_gpt = await session_service_gpt.create_session(\n",
        "        app_name=APP_NAME_GPT,\n",
        "        user_id=USER_ID_GPT,\n",
        "        session_id=SESSION_ID_GPT\n",
        "    )\n",
        "    print(f\"Session created: App='{APP_NAME_GPT}', User='{USER_ID_GPT}', Session='{SESSION_ID_GPT}'\")\n",
        "\n",
        "    # Create a runner specific to this agent and its session service\n",
        "    runner_gpt = Runner(\n",
        "        agent=weather_agent_gpt,\n",
        "        app_name=APP_NAME_GPT,       # Use the specific app name\n",
        "        session_service=session_service_gpt # Use the specific session service\n",
        "        )\n",
        "    print(f\"Runner created for agent '{runner_gpt.agent.name}'.\")\n",
        "\n",
        "    # --- Test the GPT Agent ---\n",
        "    print(\"\\n--- Testing GPT Agent ---\")\n",
        "    # Ensure call_agent_async uses the correct runner, user_id, session_id\n",
        "    await call_agent_async(query = \"What's the weather in Tokyo?\",\n",
        "                           runner=runner_gpt,\n",
        "                           user_id=USER_ID_GPT,\n",
        "                           session_id=SESSION_ID_GPT)\n",
        "    # --- OR ---\n",
        "\n",
        "    # Uncomment the following lines if running as a standard Python script (.py file):\n",
        "    # import asyncio\n",
        "    # if __name__ == \"__main__\":\n",
        "    #     try:\n",
        "    #         asyncio.run(call_agent_async(query = \"What's the weather in Tokyo?\",\n",
        "    #                      runner=runner_gpt,\n",
        "    #                       user_id=USER_ID_GPT,\n",
        "    #                       session_id=SESSION_ID_GPT)\n",
        "    #     except Exception as e:\n",
        "    #         print(f\"An error occurred: {e}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Could not create or run GPT agent '{MODEL_GPT_4O}'. Check API Key and model name. Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smrLoOJB8fDk",
        "outputId": "a31c6efe-2272-4eef-913f-c4de1bd653f5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent 'weather_agent_gpt' created using model 'openai/gpt-4.1'.\n",
            "Session created: App='weather_tutorial_app_gpt', User='user_1_gpt', Session='session_001_gpt'\n",
            "Runner created for agent 'weather_agent_gpt'.\n",
            "\n",
            "--- Testing GPT Agent ---\n",
            "\n",
            ">>> User Query: What's the weather in Tokyo?\n",
            "--- Tool: get_weather called for city: Tokyo ---\n",
            "<<< Agent Response: Tokyo is currently experiencing light rain with a temperature of 18°C.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define and Test Claude Agent\n",
        "\n",
        "# Make sure 'get_weather' function from Step 1 is defined in your environment.\n",
        "# Make sure 'call_agent_async' is defined from earlier.\n",
        "\n",
        "# --- Agent using Claude Sonnet ---\n",
        "weather_agent_claude = None # Initialize to None\n",
        "runner_claude = None      # Initialize runner to None\n",
        "\n",
        "try:\n",
        "    weather_agent_claude = Agent(\n",
        "        name=\"weather_agent_claude\",\n",
        "        # Key change: Wrap the LiteLLM model identifier\n",
        "        model=LiteLlm(model=MODEL_CLAUDE_SONNET),\n",
        "        description=\"Provides weather information (using Claude Sonnet).\",\n",
        "        instruction=\"You are a helpful weather assistant powered by Claude Sonnet. \"\n",
        "                    \"Use the 'get_weather' tool for city weather requests. \"\n",
        "                    \"Analyze the tool's dictionary output ('status', 'report'/'error_message'). \"\n",
        "                    \"Clearly present successful reports or polite error messages.\",\n",
        "        tools=[get_weather], # Re-use the same tool\n",
        "    )\n",
        "    print(f\"Agent '{weather_agent_claude.name}' created using model '{MODEL_CLAUDE_SONNET}'.\")\n",
        "\n",
        "    # InMemorySessionService is simple, non-persistent storage for this tutorial.\n",
        "    session_service_claude = InMemorySessionService() # Create a dedicated service\n",
        "\n",
        "    # Define constants for identifying the interaction context\n",
        "    APP_NAME_CLAUDE = \"weather_tutorial_app_claude\" # Unique app name\n",
        "    USER_ID_CLAUDE = \"user_1_claude\"\n",
        "    SESSION_ID_CLAUDE = \"session_001_claude\" # Using a fixed ID for simplicity\n",
        "\n",
        "    # Create the specific session where the conversation will happen\n",
        "    session_claude = await session_service_claude.create_session(\n",
        "        app_name=APP_NAME_CLAUDE,\n",
        "        user_id=USER_ID_CLAUDE,\n",
        "        session_id=SESSION_ID_CLAUDE\n",
        "    )\n",
        "    print(f\"Session created: App='{APP_NAME_CLAUDE}', User='{USER_ID_CLAUDE}', Session='{SESSION_ID_CLAUDE}'\")\n",
        "\n",
        "    # Create a runner specific to this agent and its session service\n",
        "    runner_claude = Runner(\n",
        "        agent=weather_agent_claude,\n",
        "        app_name=APP_NAME_CLAUDE,       # Use the specific app name\n",
        "        session_service=session_service_claude # Use the specific session service\n",
        "        )\n",
        "    print(f\"Runner created for agent '{runner_claude.agent.name}'.\")\n",
        "\n",
        "    # --- Test the Claude Agent ---\n",
        "    print(\"\\n--- Testing Claude Agent ---\")\n",
        "    # Ensure call_agent_async uses the correct runner, user_id, session_id\n",
        "    await call_agent_async(query = \"Weather in London please.\",\n",
        "                           runner=runner_claude,\n",
        "                           user_id=USER_ID_CLAUDE,\n",
        "                           session_id=SESSION_ID_CLAUDE)\n",
        "\n",
        "    # --- OR ---\n",
        "\n",
        "    # Uncomment the following lines if running as a standard Python script (.py file):\n",
        "    # import asyncio\n",
        "    # if __name__ == \"__main__\":\n",
        "    #     try:\n",
        "    #         asyncio.run(call_agent_async(query = \"Weather in London please.\",\n",
        "    #                      runner=runner_claude,\n",
        "    #                       user_id=USER_ID_CLAUDE,\n",
        "    #                       session_id=SESSION_ID_CLAUDE)\n",
        "    #     except Exception as e:\n",
        "    #         print(f\"An error occurred: {e}\")\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Could not create or run Claude agent '{MODEL_CLAUDE_SONNET}'. Check API Key and model name. Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hci9DvzXD89U",
        "outputId": "e2293c2a-e8e0-4df8-eb1c-ec640d44861f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent 'weather_agent_claude' created using model 'anthropic/claude-sonnet-4-20250514'.\n",
            "Session created: App='weather_tutorial_app_claude', User='user_1_claude', Session='session_001_claude'\n",
            "Runner created for agent 'weather_agent_claude'.\n",
            "\n",
            "--- Testing Claude Agent ---\n",
            "\n",
            ">>> User Query: Weather in London please.\n",
            "--- Tool: get_weather called for city: London ---\n",
            "<<< Agent Response: The current weather in London is cloudy with a temperature of 15°C (59°F). It's a typical mild day with overcast skies.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define Tools for Greeting and Farewell Agents\n",
        "from typing import Optional # Make sure to import Optional\n",
        "\n",
        "# Ensure 'get_weather' from Step 1 is available if running this step independently.\n",
        "# def get_weather(city: str) -> dict: ... (from Step 1)\n",
        "\n",
        "def say_hello(name: Optional[str] = None) -> str:\n",
        "    \"\"\"Provides a simple greeting. If a name is provided, it will be used.\n",
        "\n",
        "    Args:\n",
        "        name (str, optional): The name of the person to greet. Defaults to a generic greeting if not provided.\n",
        "\n",
        "    Returns:\n",
        "        str: A friendly greeting message.\n",
        "    \"\"\"\n",
        "    if name:\n",
        "        greeting = f\"Hello, {name}!\"\n",
        "        print(f\"--- Tool: say_hello called with name: {name} ---\")\n",
        "    else:\n",
        "        greeting = \"Hello there!\" # Default greeting if name is None or not explicitly passed\n",
        "        print(f\"--- Tool: say_hello called without a specific name (name_arg_value: {name}) ---\")\n",
        "    return greeting\n",
        "\n",
        "def say_goodbye() -> str:\n",
        "    \"\"\"Provides a simple farewell message to conclude the conversation.\"\"\"\n",
        "    print(f\"--- Tool: say_goodbye called ---\")\n",
        "    return \"Goodbye! Have a great day.\"\n",
        "\n",
        "print(\"Greeting and Farewell tools defined.\")\n",
        "\n",
        "# Optional self-test\n",
        "print(say_hello(\"Alice\"))\n",
        "print(say_hello()) # Test with no argument (should use default \"Hello there!\")\n",
        "print(say_hello(name=None)) # Test with name explicitly as None (should use default \"Hello there!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bh-ZetrZhmzQ",
        "outputId": "7145eeb7-150c-4b94-f062-f91e925799b6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greeting and Farewell tools defined.\n",
            "--- Tool: say_hello called with name: Alice ---\n",
            "Hello, Alice!\n",
            "--- Tool: say_hello called without a specific name (name_arg_value: None) ---\n",
            "Hello there!\n",
            "--- Tool: say_hello called without a specific name (name_arg_value: None) ---\n",
            "Hello there!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define Greeting and Farewell Sub-Agents\n",
        "\n",
        "# If you want to use models other than Gemini, Ensure LiteLlm is imported and API keys are set (from Step 0/2)\n",
        "# from google.adk.models.lite_llm import LiteLlm\n",
        "# MODEL_GPT_4O, MODEL_CLAUDE_SONNET etc. should be defined\n",
        "# Or else, continue to use: model = MODEL_GEMINI_2_5_FLASH\n",
        "\n",
        "# --- Greeting Agent ---\n",
        "greeting_agent = None\n",
        "try:\n",
        "    greeting_agent = Agent(\n",
        "        # Using a potentially different/cheaper model for a simple task\n",
        "        model = MODEL_GEMINI_2_5_FLASH,\n",
        "        # model=LiteLlm(model=MODEL_GPT_4O), # If you would like to experiment with other models\n",
        "        name=\"greeting_agent\",\n",
        "        instruction=\"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting to the user. \"\n",
        "                    \"Use the 'say_hello' tool to generate the greeting. \"\n",
        "                    \"If the user provides their name, make sure to pass it to the tool. \"\n",
        "                    \"Do not engage in any other conversation or tasks.\",\n",
        "        description=\"Handles simple greetings and hellos using the 'say_hello' tool.\", # Crucial for delegation\n",
        "        tools=[say_hello],\n",
        "    )\n",
        "    print(f\"✅ Agent '{greeting_agent.name}' created using model '{greeting_agent.model}'.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Could not create Greeting agent. Check API Key ({greeting_agent.model}). Error: {e}\")\n",
        "\n",
        "# --- Farewell Agent ---\n",
        "farewell_agent = None\n",
        "try:\n",
        "    farewell_agent = Agent(\n",
        "        # Can use the same or a different model\n",
        "        model = MODEL_GEMINI_2_5_FLASH,\n",
        "        # model=LiteLlm(model=MODEL_GPT_4O), # If you would like to experiment with other models\n",
        "        name=\"farewell_agent\",\n",
        "        instruction=\"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message. \"\n",
        "                    \"Use the 'say_goodbye' tool when the user indicates they are leaving or ending the conversation \"\n",
        "                    \"(e.g., using words like 'bye', 'goodbye', 'thanks bye', 'see you'). \"\n",
        "                    \"Do not perform any other actions.\",\n",
        "        description=\"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\", # Crucial for delegation\n",
        "        tools=[say_goodbye],\n",
        "    )\n",
        "    print(f\"✅ Agent '{farewell_agent.name}' created using model '{farewell_agent.model}'.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Could not create Farewell agent. Check API Key ({farewell_agent.model}). Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91PWiI6kiTvS",
        "outputId": "b5a4dc08-2ec4-4e98-9e04-29063a4e278a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Agent 'greeting_agent' created using model 'gemini-2.5-flash'.\n",
            "✅ Agent 'farewell_agent' created using model 'gemini-2.5-flash'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define the Root Agent with Sub-Agents\n",
        "\n",
        "# Ensure sub-agents were created successfully before defining the root agent.\n",
        "# Also ensure the original 'get_weather' tool is defined.\n",
        "root_agent = None\n",
        "runner_root = None # Initialize runner\n",
        "\n",
        "if greeting_agent and farewell_agent and 'get_weather' in globals():\n",
        "    # Let's use a capable Gemini model for the root agent to handle orchestration\n",
        "    root_agent_model = MODEL_GEMINI_2_5_FLASH\n",
        "\n",
        "    weather_agent_team = Agent(\n",
        "        name=\"weather_agent_v2\", # Give it a new version name\n",
        "        model=root_agent_model,\n",
        "        description=\"The main coordinator agent. Handles weather requests and delegates greetings/farewells to specialists.\",\n",
        "        instruction=\"You are the main Weather Agent coordinating a team. Your primary responsibility is to provide weather information. \"\n",
        "                    \"Use the 'get_weather' tool ONLY for specific weather requests (e.g., 'weather in London'). \"\n",
        "                    \"You have specialized sub-agents: \"\n",
        "                    \"1. 'greeting_agent': Handles simple greetings like 'Hi', 'Hello'. Delegate to it for these. \"\n",
        "                    \"2. 'farewell_agent': Handles simple farewells like 'Bye', 'See you'. Delegate to it for these. \"\n",
        "                    \"Analyze the user's query. If it's a greeting, delegate to 'greeting_agent'. If it's a farewell, delegate to 'farewell_agent'. \"\n",
        "                    \"If it's a weather request, handle it yourself using 'get_weather'. \"\n",
        "                    \"For anything else, respond appropriately or state you cannot handle it.\",\n",
        "        tools=[get_weather], # Root agent still needs the weather tool for its core task\n",
        "        # Key change: Link the sub-agents here!\n",
        "        sub_agents=[greeting_agent, farewell_agent]\n",
        "    )\n",
        "    print(f\"✅ Root Agent '{weather_agent_team.name}' created using model '{root_agent_model}' with sub-agents: {[sa.name for sa in weather_agent_team.sub_agents]}\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ Cannot create root agent because one or more sub-agents failed to initialize or 'get_weather' tool is missing.\")\n",
        "    if not greeting_agent: print(\" - Greeting Agent is missing.\")\n",
        "    if not farewell_agent: print(\" - Farewell Agent is missing.\")\n",
        "    if 'get_weather' not in globals(): print(\" - get_weather function is missing.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVV1dgeAoyN7",
        "outputId": "d612ef88-b385-4a7f-90db-feb20a034bcc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Root Agent 'weather_agent_v2' created using model 'gemini-2.5-flash' with sub-agents: ['greeting_agent', 'farewell_agent']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Interact with the Agent Team\n",
        "import asyncio # Ensure asyncio is imported\n",
        "\n",
        "# Ensure the root agent (e.g., 'weather_agent_team' or 'root_agent' from the previous cell) is defined.\n",
        "# Ensure the call_agent_async function is defined.\n",
        "\n",
        "# Check if the root agent variable exists before defining the conversation function\n",
        "root_agent_var_name = 'root_agent' # Default name from Step 3 guide\n",
        "if 'weather_agent_team' in globals(): # Check if user used this name instead\n",
        "    root_agent_var_name = 'weather_agent_team'\n",
        "elif 'root_agent' not in globals():\n",
        "    print(\"⚠️ Root agent ('root_agent' or 'weather_agent_team') not found. Cannot define run_team_conversation.\")\n",
        "    # Assign a dummy value to prevent NameError later if the code block runs anyway\n",
        "    root_agent = None # Or set a flag to prevent execution\n",
        "\n",
        "# Only define and run if the root agent exists\n",
        "if root_agent_var_name in globals() and globals()[root_agent_var_name]:\n",
        "    # Define the main async function for the conversation logic.\n",
        "    # The 'await' keywords INSIDE this function are necessary for async operations.\n",
        "    async def run_team_conversation():\n",
        "        print(\"\\n--- Testing Agent Team Delegation ---\")\n",
        "        session_service = InMemorySessionService()\n",
        "        APP_NAME = \"weather_tutorial_agent_team\"\n",
        "        USER_ID = \"user_1_agent_team\"\n",
        "        SESSION_ID = \"session_001_agent_team\"\n",
        "        session = await session_service.create_session(\n",
        "            app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
        "        )\n",
        "        print(f\"Session created: App='{APP_NAME}', User='{USER_ID}', Session='{SESSION_ID}'\")\n",
        "\n",
        "        actual_root_agent = globals()[root_agent_var_name]\n",
        "        runner_agent_team = Runner( # Or use InMemoryRunner\n",
        "            agent=actual_root_agent,\n",
        "            app_name=APP_NAME,\n",
        "            session_service=session_service\n",
        "        )\n",
        "        print(f\"Runner created for agent '{actual_root_agent.name}'.\")\n",
        "\n",
        "        # --- Interactions using await (correct within async def) ---\n",
        "        await call_agent_async(query = \"Hello there!\",\n",
        "                               runner=runner_agent_team,\n",
        "                               user_id=USER_ID,\n",
        "                               session_id=SESSION_ID)\n",
        "        await call_agent_async(query = \"What is the weather in New York?\",\n",
        "                               runner=runner_agent_team,\n",
        "                               user_id=USER_ID,\n",
        "                               session_id=SESSION_ID)\n",
        "        await call_agent_async(query = \"Thanks, bye!\",\n",
        "                               runner=runner_agent_team,\n",
        "                               user_id=USER_ID,\n",
        "                               session_id=SESSION_ID)\n",
        "\n",
        "    # --- Execute the `run_team_conversation` async function ---\n",
        "    # Choose ONE of the methods below based on your environment.\n",
        "    # Note: This may require API keys for the models used!\n",
        "\n",
        "    # METHOD 1: Direct await (Default for Notebooks/Async REPLs)\n",
        "    # If your environment supports top-level await (like Colab/Jupyter notebooks),\n",
        "    # it means an event loop is already running, so you can directly await the function.\n",
        "    print(\"Attempting execution using 'await' (default for notebooks)...\")\n",
        "    await run_team_conversation()\n",
        "\n",
        "    # METHOD 2: asyncio.run (For Standard Python Scripts [.py])\n",
        "    # If running this code as a standard Python script from your terminal,\n",
        "    # the script context is synchronous. `asyncio.run()` is needed to\n",
        "    # create and manage an event loop to execute your async function.\n",
        "    # To use this method:\n",
        "    # 1. Comment out the `await run_team_conversation()` line above.\n",
        "    # 2. Uncomment the following block:\n",
        "    \"\"\"\n",
        "    import asyncio\n",
        "    if __name__ == \"__main__\": # Ensures this runs only when script is executed directly\n",
        "        print(\"Executing using 'asyncio.run()' (for standard Python scripts)...\")\n",
        "        try:\n",
        "            # This creates an event loop, runs your async function, and closes the loop.\n",
        "            asyncio.run(run_team_conversation())\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "    \"\"\"\n",
        "\n",
        "else:\n",
        "    # This message prints if the root agent variable wasn't found earlier\n",
        "    print(\"\\n⚠️ Skipping agent team conversation execution as the root agent was not successfully defined in a previous step.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skJrwA7fp3ee",
        "outputId": "4c4a9c80-3706-4ddb-ea72-4a3d9e086548"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting execution using 'await' (default for notebooks)...\n",
            "\n",
            "--- Testing Agent Team Delegation ---\n",
            "Session created: App='weather_tutorial_agent_team', User='user_1_agent_team', Session='session_001_agent_team'\n",
            "Runner created for agent 'weather_agent_v2'.\n",
            "\n",
            ">>> User Query: Hello there!\n",
            "--- Tool: say_hello called without a specific name (name_arg_value: None) ---\n",
            "<<< Agent Response: Hello there!\n",
            "\n",
            "\n",
            ">>> User Query: What is the weather in New York?\n",
            "--- Tool: get_weather called for city: New York ---\n",
            "<<< Agent Response: The weather in New York is sunny with a temperature of 25°C.\n",
            "\n",
            ">>> User Query: Thanks, bye!\n",
            "--- Tool: say_goodbye called ---\n",
            "<<< Agent Response: Goodbye! Have a great day.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1. Initialize New Session Service and State\n",
        "\n",
        "# Import necessary session components\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "\n",
        "# Create a NEW session service instance for this state demonstration\n",
        "session_service_stateful = InMemorySessionService()\n",
        "print(\"✅ New InMemorySessionService created for state demonstration.\")\n",
        "\n",
        "# Define a NEW session ID for this part of the tutorial\n",
        "SESSION_ID_STATEFUL = \"session_state_demo_001\"\n",
        "USER_ID_STATEFUL = \"user_state_demo\"\n",
        "\n",
        "# Define initial state data - user prefers Celsius initially\n",
        "initial_state = {\n",
        "    \"user_preference_temperature_unit\": \"Celsius\"\n",
        "}\n",
        "\n",
        "# Create the session, providing the initial state\n",
        "session_stateful = await session_service_stateful.create_session(\n",
        "    app_name=APP_NAME, # Use the consistent app name\n",
        "    user_id=USER_ID_STATEFUL,\n",
        "    session_id=SESSION_ID_STATEFUL,\n",
        "    state=initial_state # <<< Initialize state during creation\n",
        ")\n",
        "print(f\"✅ Session '{SESSION_ID_STATEFUL}' created for user '{USER_ID_STATEFUL}'.\")\n",
        "\n",
        "# Verify the initial state was set correctly\n",
        "retrieved_session = await session_service_stateful.get_session(app_name=APP_NAME,\n",
        "                                                         user_id=USER_ID_STATEFUL,\n",
        "                                                         session_id = SESSION_ID_STATEFUL)\n",
        "print(\"\\n--- Initial Session State ---\")\n",
        "if retrieved_session:\n",
        "    print(retrieved_session.state)\n",
        "else:\n",
        "    print(\"Error: Could not retrieve session.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV7tuTmFxQY4",
        "outputId": "c4b51d98-44ac-49ee-d952-67b955ec9c3f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ New InMemorySessionService created for state demonstration.\n",
            "✅ Session 'session_state_demo_001' created for user 'user_state_demo'.\n",
            "\n",
            "--- Initial Session State ---\n",
            "{'user_preference_temperature_unit': 'Celsius'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.adk.tools.tool_context import ToolContext\n",
        "\n",
        "def get_weather_stateful(city: str, tool_context: ToolContext) -> dict:\n",
        "    \"\"\"Retrieves weather, converts temp unit based on session state.\"\"\"\n",
        "    print(f\"--- Tool: get_weather_stateful called for {city} ---\")\n",
        "\n",
        "    # --- Read preference from state ---\n",
        "    preferred_unit = tool_context.state.get(\"user_preference_temperature_unit\", \"Celsius\") # Default to Celsius\n",
        "    print(f\"--- Tool: Reading state 'user_preference_temperature_unit': {preferred_unit} ---\")\n",
        "\n",
        "    city_normalized = city.lower().replace(\" \", \"\")\n",
        "\n",
        "    # Mock weather data (always stored in Celsius internally)\n",
        "    mock_weather_db = {\n",
        "        \"newyork\": {\"temp_c\": 25, \"condition\": \"sunny\"},\n",
        "        \"london\": {\"temp_c\": 15, \"condition\": \"cloudy\"},\n",
        "        \"tokyo\": {\"temp_c\": 18, \"condition\": \"light rain\"},\n",
        "    }\n",
        "\n",
        "    if city_normalized in mock_weather_db:\n",
        "        data = mock_weather_db[city_normalized]\n",
        "        temp_c = data[\"temp_c\"]\n",
        "        condition = data[\"condition\"]\n",
        "\n",
        "        # Format temperature based on state preference\n",
        "        if preferred_unit == \"Fahrenheit\":\n",
        "            temp_value = (temp_c * 9/5) + 32 # Calculate Fahrenheit\n",
        "            temp_unit = \"°F\"\n",
        "        else: # Default to Celsius\n",
        "            temp_value = temp_c\n",
        "            temp_unit = \"°C\"\n",
        "\n",
        "        report = f\"The weather in {city.capitalize()} is {condition} with a temperature of {temp_value:.0f}{temp_unit}.\"\n",
        "        result = {\"status\": \"success\", \"report\": report}\n",
        "        print(f\"--- Tool: Generated report in {preferred_unit}. Result: {result} ---\")\n",
        "\n",
        "        # Example of writing back to state (optional for this tool)\n",
        "        tool_context.state[\"last_city_checked_stateful\"] = city\n",
        "        print(f\"--- Tool: Updated state 'last_city_checked_stateful': {city} ---\")\n",
        "\n",
        "        return result\n",
        "    else:\n",
        "        # Handle city not found\n",
        "        error_msg = f\"Sorry, I don't have weather information for '{city}'.\"\n",
        "        print(f\"--- Tool: City '{city}' not found. ---\")\n",
        "        return {\"status\": \"error\", \"error_message\": error_msg}\n",
        "\n",
        "print(\"✅ State-aware 'get_weather_stateful' tool defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oTocp7jzIOe",
        "outputId": "7b317b91-789f-40dc-d95f-5658ab8793e6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ State-aware 'get_weather_stateful' tool defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3. Redefine Sub-Agents and Update Root Agent with output_key\n",
        "\n",
        "# Ensure necessary imports: Agent, LiteLlm, Runner\n",
        "from google.adk.agents import Agent\n",
        "from google.adk.models.lite_llm import LiteLlm\n",
        "from google.adk.runners import Runner\n",
        "# Ensure tools 'say_hello', 'say_goodbye' are defined (from Step 3)\n",
        "# Ensure model constants MODEL_GPT_4O, MODEL_GEMINI_2_5_FLASH etc. are defined\n",
        "\n",
        "# --- Redefine Greeting Agent (from Step 3) ---\n",
        "greeting_agent = None\n",
        "try:\n",
        "    greeting_agent = Agent(\n",
        "        model=MODEL_GEMINI_2_5_FLASH,\n",
        "        name=\"greeting_agent\",\n",
        "        instruction=\"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting using the 'say_hello' tool. Do nothing else.\",\n",
        "        description=\"Handles simple greetings and hellos using the 'say_hello' tool.\",\n",
        "        tools=[say_hello],\n",
        "    )\n",
        "    print(f\"✅ Agent '{greeting_agent.name}' redefined.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Could not redefine Greeting agent. Error: {e}\")\n",
        "\n",
        "# --- Redefine Farewell Agent (from Step 3) ---\n",
        "farewell_agent = None\n",
        "try:\n",
        "    farewell_agent = Agent(\n",
        "        model=MODEL_GEMINI_2_5_FLASH,\n",
        "        name=\"farewell_agent\",\n",
        "        instruction=\"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message using the 'say_goodbye' tool. Do not perform any other actions.\",\n",
        "        description=\"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\",\n",
        "        tools=[say_goodbye],\n",
        "    )\n",
        "    print(f\"✅ Agent '{farewell_agent.name}' redefined.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Could not redefine Farewell agent. Error: {e}\")\n",
        "\n",
        "# --- Define the Updated Root Agent ---\n",
        "root_agent_stateful = None\n",
        "runner_root_stateful = None # Initialize runner\n",
        "\n",
        "# Check prerequisites before creating the root agent\n",
        "if greeting_agent and farewell_agent and 'get_weather_stateful' in globals():\n",
        "\n",
        "    root_agent_model = MODEL_GEMINI_2_5_FLASH # Choose orchestration model\n",
        "\n",
        "    root_agent_stateful = Agent(\n",
        "        name=\"weather_agent_v4_stateful\", # New version name\n",
        "        model=root_agent_model,\n",
        "        description=\"Main agent: Provides weather (state-aware unit), delegates greetings/farewells, saves report to state.\",\n",
        "        instruction=\"You are the main Weather Agent. Your job is to provide weather using 'get_weather_stateful'. \"\n",
        "                    \"The tool will format the temperature based on user preference stored in state. \"\n",
        "                    \"Delegate simple greetings to 'greeting_agent' and farewells to 'farewell_agent'. \"\n",
        "                    \"Handle only weather requests, greetings, and farewells.\",\n",
        "        tools=[get_weather_stateful], # Use the state-aware tool\n",
        "        sub_agents=[greeting_agent, farewell_agent], # Include sub-agents\n",
        "        output_key=\"last_weather_report\" # <<< Auto-save agent's final weather response\n",
        "    )\n",
        "    print(f\"✅ Root Agent '{root_agent_stateful.name}' created using stateful tool and output_key.\")\n",
        "\n",
        "    # --- Create Runner for this Root Agent & NEW Session Service ---\n",
        "    runner_root_stateful = Runner(\n",
        "        agent=root_agent_stateful,\n",
        "        app_name=APP_NAME,\n",
        "        session_service=session_service_stateful # Use the NEW stateful session service\n",
        "    )\n",
        "    print(f\"✅ Runner created for stateful root agent '{runner_root_stateful.agent.name}' using stateful session service.\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ Cannot create stateful root agent. Prerequisites missing.\")\n",
        "    if not greeting_agent: print(\" - greeting_agent definition missing.\")\n",
        "    if not farewell_agent: print(\" - farewell_agent definition missing.\")\n",
        "    if 'get_weather_stateful' not in globals(): print(\" - get_weather_stateful tool missing.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lvyUNBP0nM3",
        "outputId": "a4841a2f-372b-4dee-f21a-bf1489270c28"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Agent 'greeting_agent' redefined.\n",
            "✅ Agent 'farewell_agent' redefined.\n",
            "✅ Root Agent 'weather_agent_v4_stateful' created using stateful tool and output_key.\n",
            "✅ Runner created for stateful root agent 'weather_agent_v4_stateful' using stateful session service.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. Interact to Test State Flow and output_key\n",
        "import asyncio # Ensure asyncio is imported\n",
        "\n",
        "# Ensure the stateful runner (runner_root_stateful) is available from the previous cell\n",
        "# Ensure call_agent_async, USER_ID_STATEFUL, SESSION_ID_STATEFUL, APP_NAME are defined\n",
        "\n",
        "if 'runner_root_stateful' in globals() and runner_root_stateful:\n",
        "    # Define the main async function for the stateful conversation logic.\n",
        "    # The 'await' keywords INSIDE this function are necessary for async operations.\n",
        "    async def run_stateful_conversation():\n",
        "        print(\"\\n--- Testing State: Temp Unit Conversion & output_key ---\")\n",
        "\n",
        "        # 1. Check weather (Uses initial state: Celsius)\n",
        "        print(\"--- Turn 1: Requesting weather in London (expect Celsius) ---\")\n",
        "        await call_agent_async(query= \"What's the weather in London?\",\n",
        "                               runner=runner_root_stateful,\n",
        "                               user_id=USER_ID_STATEFUL,\n",
        "                               session_id=SESSION_ID_STATEFUL\n",
        "                              )\n",
        "\n",
        "        # 2. Manually update state preference to Fahrenheit - DIRECTLY MODIFY STORAGE\n",
        "        print(\"\\n--- Manually Updating State: Setting unit to Fahrenheit ---\")\n",
        "        try:\n",
        "            # Access the internal storage directly - THIS IS SPECIFIC TO InMemorySessionService for testing\n",
        "            # NOTE: In production with persistent services (Database, VertexAI), you would\n",
        "            # typically update state via agent actions or specific service APIs if available,\n",
        "            # not by direct manipulation of internal storage.\n",
        "            stored_session = session_service_stateful.sessions[APP_NAME][USER_ID_STATEFUL][SESSION_ID_STATEFUL]\n",
        "            stored_session.state[\"user_preference_temperature_unit\"] = \"Fahrenheit\"\n",
        "            # Optional: You might want to update the timestamp as well if any logic depends on it\n",
        "            # import time\n",
        "            # stored_session.last_update_time = time.time()\n",
        "            print(f\"--- Stored session state updated. Current 'user_preference_temperature_unit': {stored_session.state.get('user_preference_temperature_unit', 'Not Set')} ---\") # Added .get for safety\n",
        "        except KeyError:\n",
        "            print(f\"--- Error: Could not retrieve session '{SESSION_ID_STATEFUL}' from internal storage for user '{USER_ID_STATEFUL}' in app '{APP_NAME}' to update state. Check IDs and if session was created. ---\")\n",
        "        except Exception as e:\n",
        "             print(f\"--- Error updating internal session state: {e} ---\")\n",
        "\n",
        "        # 3. Check weather again (Tool should now use Fahrenheit)\n",
        "        # This will also update 'last_weather_report' via output_key\n",
        "        print(\"\\n--- Turn 2: Requesting weather in New York (expect Fahrenheit) ---\")\n",
        "        await call_agent_async(query= \"Tell me the weather in New York.\",\n",
        "                               runner=runner_root_stateful,\n",
        "                               user_id=USER_ID_STATEFUL,\n",
        "                               session_id=SESSION_ID_STATEFUL\n",
        "                              )\n",
        "\n",
        "        # 4. Test basic delegation (should still work)\n",
        "        # This will update 'last_weather_report' again, overwriting the NY weather report\n",
        "        print(\"\\n--- Turn 3: Sending a greeting ---\")\n",
        "        await call_agent_async(query= \"Hi!\",\n",
        "                               runner=runner_root_stateful,\n",
        "                               user_id=USER_ID_STATEFUL,\n",
        "                               session_id=SESSION_ID_STATEFUL\n",
        "                              )\n",
        "\n",
        "    # --- Execute the `run_stateful_conversation` async function ---\n",
        "    # Choose ONE of the methods below based on your environment.\n",
        "\n",
        "    # METHOD 1: Direct await (Default for Notebooks/Async REPLs)\n",
        "    # If your environment supports top-level await (like Colab/Jupyter notebooks),\n",
        "    # it means an event loop is already running, so you can directly await the function.\n",
        "    print(\"Attempting execution using 'await' (default for notebooks)...\")\n",
        "    await run_stateful_conversation()\n",
        "\n",
        "    # METHOD 2: asyncio.run (For Standard Python Scripts [.py])\n",
        "    # If running this code as a standard Python script from your terminal,\n",
        "    # the script context is synchronous. `asyncio.run()` is needed to\n",
        "    # create and manage an event loop to execute your async function.\n",
        "    # To use this method:\n",
        "    # 1. Comment out the `await run_stateful_conversation()` line above.\n",
        "    # 2. Uncomment the following block:\n",
        "    \"\"\"\n",
        "    import asyncio\n",
        "    if __name__ == \"__main__\": # Ensures this runs only when script is executed directly\n",
        "        print(\"Executing using 'asyncio.run()' (for standard Python scripts)...\")\n",
        "        try:\n",
        "            # This creates an event loop, runs your async function, and closes the loop.\n",
        "            asyncio.run(run_stateful_conversation())\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "    \"\"\"\n",
        "\n",
        "    # --- Inspect final session state after the conversation ---\n",
        "    # This block runs after either execution method completes.\n",
        "    print(\"\\n--- Inspecting Final Session State ---\")\n",
        "    final_session = await session_service_stateful.get_session(app_name=APP_NAME,\n",
        "                                                         user_id= USER_ID_STATEFUL,\n",
        "                                                         session_id=SESSION_ID_STATEFUL)\n",
        "    if final_session:\n",
        "        # Use .get() for safer access to potentially missing keys\n",
        "        print(f\"Final Preference: {final_session.state.get('user_preference_temperature_unit', 'Not Set')}\")\n",
        "        print(f\"Final Last Weather Report (from output_key): {final_session.state.get('last_weather_report', 'Not Set')}\")\n",
        "        print(f\"Final Last City Checked (by tool): {final_session.state.get('last_city_checked_stateful', 'Not Set')}\")\n",
        "        # Print full state for detailed view\n",
        "        # print(f\"Full State Dict: {final_session.state}\") # For detailed view\n",
        "    else:\n",
        "        print(\"\\n❌ Error: Could not retrieve final session state.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n⚠️ Skipping state test conversation. Stateful root agent runner ('runner_root_stateful') is not available.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0IMzK8b8VOi",
        "outputId": "59bcce72-3ce9-4297-f6c1-9a4994571625"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting execution using 'await' (default for notebooks)...\n",
            "\n",
            "--- Testing State: Temp Unit Conversion & output_key ---\n",
            "--- Turn 1: Requesting weather in London (expect Celsius) ---\n",
            "\n",
            ">>> User Query: What's the weather in London?\n",
            "--- Tool: get_weather_stateful called for London ---\n",
            "--- Tool: Reading state 'user_preference_temperature_unit': Celsius ---\n",
            "--- Tool: Generated report in Celsius. Result: {'status': 'success', 'report': 'The weather in London is cloudy with a temperature of 15°C.'} ---\n",
            "--- Tool: Updated state 'last_city_checked_stateful': London ---\n",
            "<<< Agent Response: The weather in London is cloudy with a temperature of 15°C.\n",
            "\n",
            "--- Manually Updating State: Setting unit to Fahrenheit ---\n",
            "--- Stored session state updated. Current 'user_preference_temperature_unit': Fahrenheit ---\n",
            "\n",
            "--- Turn 2: Requesting weather in New York (expect Fahrenheit) ---\n",
            "\n",
            ">>> User Query: Tell me the weather in New York.\n",
            "--- Tool: get_weather_stateful called for New York ---\n",
            "--- Tool: Reading state 'user_preference_temperature_unit': Fahrenheit ---\n",
            "--- Tool: Generated report in Fahrenheit. Result: {'status': 'success', 'report': 'The weather in New york is sunny with a temperature of 77°F.'} ---\n",
            "--- Tool: Updated state 'last_city_checked_stateful': New York ---\n",
            "<<< Agent Response: The weather in New york is sunny with a temperature of 77°F.\n",
            "\n",
            "--- Turn 3: Sending a greeting ---\n",
            "\n",
            ">>> User Query: Hi!\n",
            "--- Tool: say_hello called without a specific name (name_arg_value: None) ---\n",
            "<<< Agent Response: Hello there!\n",
            "\n",
            "--- Inspecting Final Session State ---\n",
            "Final Preference: Fahrenheit\n",
            "Final Last Weather Report (from output_key): The weather in New york is sunny with a temperature of 77°F.\n",
            "Final Last City Checked (by tool): New York\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "758395a5"
      },
      "source": [
        "After running the cell above, you can verify that the environment variable is set by trying to access it, for example:"
      ]
    }
  ]
}